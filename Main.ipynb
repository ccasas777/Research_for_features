{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your images at the './object_detection/images' \n",
    "\n",
    "and seperating it to two parts 'train' and 'test'\n",
    "\n",
    "\n",
    "using the labelImg to creat the xml files for the images\n",
    "\n",
    "Link:\"https://github.com/tzutalin/labelImg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert .xml files to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From object_detection/xml-to-csv.py:43: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/xml-to-csv.py     \\\n",
    "             --xml_input=images/train     \\\n",
    "             --output_path=data/train.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From object_detection/xml-to-csv.py:43: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/xml-to-csv.py     \\\n",
    "             --xml_input=images/test     \\\n",
    "             --output_path=data/test.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to TFRecord format (.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: C:\\Users\\ijan\\Desktop\\Research\\object_detection\\data/train.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From object_detection/generate_TFR.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/generate_TFR.py:82: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1128 20:55:14.339492  4016 deprecation_wrapper.py:119] From object_detection/generate_TFR.py:82: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/generate_TFR.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1128 20:55:14.361469  4016 deprecation_wrapper.py:119] From object_detection/generate_TFR.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/generate_TFR.py     \\\n",
    "             --csv_input=data/train.csv      \\\n",
    "             --output_path=data/train.record \\\n",
    "             --img_path=images/train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: C:\\Users\\ijan\\Desktop\\Research\\object_detection\\data/test.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From object_detection/generate_TFR.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/generate_TFR.py:82: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1128 20:55:16.632342  5640 deprecation_wrapper.py:119] From object_detection/generate_TFR.py:82: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/generate_TFR.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1128 20:55:16.640315  5640 deprecation_wrapper.py:119] From object_detection/generate_TFR.py:41: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/generate_TFR.py     \\\n",
    "             --csv_input=data/test.csv       \\\n",
    "             --output_path=data/test.record  \\\n",
    "              --img_path=images/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the items in Pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "\n",
      "name: \"red\"\n",
      "\n",
      "id: 1\n",
      "\n",
      "display_name: \"red\"\n",
      "\n",
      "}\n",
      "\n",
      "item {\n",
      "\n",
      "name: \"green\"\n",
      "\n",
      "id: 2\n",
      "\n",
      "display_name: \"green\"\n",
      "\n",
      "}\n",
      "\n",
      "item {\n",
      "\n",
      "name: \"yellow\"\n",
      "\n",
      "id: 3\n",
      "\n",
      "display_name: \"yellow\"\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('./object_detection/data/traffic_light.pbtxt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From object_detection/train.py:51: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/train.py:53: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "2020-11-28 20:55:18.812632: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-11-28 20:55:18.814858: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\n",
      "2020-11-28 20:55:18.828617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 20:55:18.828629: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 20:55:18.828663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 20:55:19.180778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-28 20:55:19.180792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-11-28 20:55:19.180796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-11-28 20:55:19.180907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4767 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From object_detection/train.py:63: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/train.py:63: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/train.py:192: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\absl\\app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W1128 20:55:20.052867 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\absl\\app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "WARNING:tensorflow:From object_detection/train.py:98: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1128 20:55:20.053864 14512 deprecation_wrapper.py:119] From object_detection/train.py:98: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From object_detection/train.py:103: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "W1128 20:55:20.056856 14512 deprecation_wrapper.py:119] From object_detection/train.py:103: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\legacy\\trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "W1128 20:55:20.066718 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\legacy\\trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\data_decoders\\tf_example_decoder.py:189: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1128 20:55:20.070688 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\data_decoders\\tf_example_decoder.py:189: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\data_decoders\\tf_example_decoder.py:204: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W1128 20:55:20.070688 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\data_decoders\\tf_example_decoder.py:204: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:149: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1128 20:55:20.083653 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:149: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading unweighted datasets: ['object_detection/data/train.record']\n",
      "I1128 20:55:20.083653 14512 dataset_builder.py:149] Reading unweighted datasets: ['object_detection/data/train.record']\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:77: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W1128 20:55:20.083653 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:77: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "INFO:tensorflow:Reading record datasets for input file: ['object_detection/data/train.record']\n",
      "I1128 20:55:20.085571 14512 dataset_builder.py:78] Reading record datasets for input file: ['object_detection/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1128 20:55:20.085571 14512 dataset_builder.py:79] Number of filenames to read: 1\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:86: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W1128 20:55:20.085571 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:86: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1128 20:55:20.085571 14512 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W1128 20:55:20.090589 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:223: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1128 20:55:20.112533 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:223: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W1128 20:55:20.301026 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:49: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:50: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1128 20:55:20.309005 14512 deprecation_wrapper.py:119] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\builders\\dataset_builder.py:50: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1128 20:55:20.357843 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\box_list_ops.py:234: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1128 20:55:20.380813 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\box_list_ops.py:234: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "W1128 20:55:21.083935 14512 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1128 20:55:21.088921 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1128 20:55:21.089916 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.562333 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.593251 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.625165 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.655085 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.686003 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 20:55:23.715922 14512 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1128 20:55:26.642097 14512 deprecation.py:506] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W1128 20:55:27.742155 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tf_slim-1.1.0-py3.6.egg\\tf_slim\\learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "W1128 20:55:31.272713 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tf_slim-1.1.0-py3.6.egg\\tf_slim\\learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "2020-11-28 20:55:35.777047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 20:55:35.777061: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 20:55:35.777085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 20:55:35.777108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-28 20:55:35.777113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-11-28 20:55:35.777115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-11-28 20:55:35.777172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4767 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W1128 20:55:35.780626 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from object_detection/training/model.ckpt-20\n",
      "I1128 20:55:35.783634 14512 saver.py:1280] Restoring parameters from object_detection/training/model.ckpt-20\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W1128 20:55:36.506424 14512 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1128 20:55:36.510701 14512 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1128 20:55:36.772015 14512 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "I1128 20:55:54.417174 14512 learning.py:746] Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path object_detection/training/model.ckpt\n",
      "I1128 20:55:54.565759  8644 supervisor.py:1117] Saving checkpoint to path object_detection/training/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "I1128 20:55:54.569734 14512 learning.py:760] Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "I1128 20:55:57.160805 14452 supervisor.py:1099] global_step/sec: 0\n",
      "2020-11-28 20:56:02.836614: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.836644: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.836679: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.836690: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.839046: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.839058: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.839136: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.839147: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.925050: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.925069: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.925234: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.925246: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.934806: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.934819: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.960452: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.960467: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.970670: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.970687: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.970713: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.970724: W tensorflow/core/common_runtime/bfc_allocator.cc:237] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-11-28 20:56:02.981226: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:02.981252: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.007226: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.042359: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.042395: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.043222: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.048316: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "INFO:tensorflow:Recording summary at step 20.\n",
      "I1128 20:56:03.629504 13864 supervisor.py:1050] Recording summary at step 20.\n",
      "2020-11-28 20:56:03.739604: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.739634: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.745441: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.745461: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.800374: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.800405: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.805031: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.805076: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.863637: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.863667: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.871145: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.871168: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.938603: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.938655: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.947916: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.947957: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.968241: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:03.968266: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:04.024313: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2020-11-28 20:56:04.024368: E tensorflow/stream_executor/cuda/cuda_driver.cc:828] failed to allocate 2.37G (2546794496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "INFO:tensorflow:global step 21: loss = 9.9066 (9.550 sec/step)\n",
      "I1128 20:56:04.279797 14512 learning.py:512] global step 21: loss = 9.9066 (9.550 sec/step)\n",
      "INFO:tensorflow:global step 22: loss = 10.0917 (0.391 sec/step)\n",
      "I1128 20:56:04.862239 14512 learning.py:512] global step 22: loss = 10.0917 (0.391 sec/step)\n",
      "INFO:tensorflow:global step 23: loss = 9.1665 (0.394 sec/step)\n",
      "I1128 20:56:05.320011 14512 learning.py:512] global step 23: loss = 9.1665 (0.394 sec/step)\n",
      "INFO:tensorflow:global step 24: loss = 8.9989 (0.394 sec/step)\n",
      "I1128 20:56:05.745877 14512 learning.py:512] global step 24: loss = 8.9989 (0.394 sec/step)\n",
      "INFO:tensorflow:global step 25: loss = 8.5117 (0.394 sec/step)\n",
      "I1128 20:56:06.202650 14512 learning.py:512] global step 25: loss = 8.5117 (0.394 sec/step)\n",
      "INFO:tensorflow:global step 26: loss = 9.1131 (0.396 sec/step)\n",
      "I1128 20:56:06.629513 14512 learning.py:512] global step 26: loss = 9.1131 (0.396 sec/step)\n",
      "INFO:tensorflow:global step 27: loss = 8.4905 (0.389 sec/step)\n",
      "I1128 20:56:07.066340 14512 learning.py:512] global step 27: loss = 8.4905 (0.389 sec/step)\n",
      "INFO:tensorflow:global step 28: loss = 8.3897 (0.394 sec/step)\n",
      "I1128 20:56:07.492174 14512 learning.py:512] global step 28: loss = 8.3897 (0.394 sec/step)\n",
      "INFO:tensorflow:global step 29: loss = 8.8106 (0.394 sec/step)\n",
      "I1128 20:56:07.933994 14512 learning.py:512] global step 29: loss = 8.8106 (0.394 sec/step)\n",
      "INFO:tensorflow:global step 30: loss = 9.3899 (0.397 sec/step)\n",
      "I1128 20:56:08.362878 14512 learning.py:512] global step 30: loss = 9.3899 (0.397 sec/step)\n",
      "INFO:tensorflow:global step 31: loss = 9.4462 (0.375 sec/step)\n",
      "I1128 20:56:08.784749 14512 learning.py:512] global step 31: loss = 9.4462 (0.375 sec/step)\n",
      "INFO:tensorflow:global step 32: loss = 8.9186 (0.398 sec/step)\n",
      "I1128 20:56:09.217560 14512 learning.py:512] global step 32: loss = 8.9186 (0.398 sec/step)\n",
      "INFO:tensorflow:global step 33: loss = 8.1216 (0.373 sec/step)\n",
      "I1128 20:56:09.591561 14512 learning.py:512] global step 33: loss = 8.1216 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 34: loss = 8.3571 (0.357 sec/step)\n",
      "I1128 20:56:09.949602 14512 learning.py:512] global step 34: loss = 8.3571 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 35: loss = 7.2487 (0.365 sec/step)\n",
      "I1128 20:56:10.316621 14512 learning.py:512] global step 35: loss = 7.2487 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 36: loss = 9.2536 (0.361 sec/step)\n",
      "I1128 20:56:10.679650 14512 learning.py:512] global step 36: loss = 9.2536 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 37: loss = 7.4912 (0.362 sec/step)\n",
      "I1128 20:56:11.043535 14512 learning.py:512] global step 37: loss = 7.4912 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 38: loss = 7.5867 (0.356 sec/step)\n",
      "I1128 20:56:11.399570 14512 learning.py:512] global step 38: loss = 7.5867 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 39: loss = 8.0353 (0.369 sec/step)\n",
      "I1128 20:56:11.770577 14512 learning.py:512] global step 39: loss = 8.0353 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 40: loss = 7.2928 (0.364 sec/step)\n",
      "I1128 20:56:12.135922 14512 learning.py:512] global step 40: loss = 7.2928 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 41: loss = 8.2624 (0.364 sec/step)\n",
      "I1128 20:56:12.499952 14512 learning.py:512] global step 41: loss = 8.2624 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 42: loss = 8.5842 (0.365 sec/step)\n",
      "I1128 20:56:12.866973 14512 learning.py:512] global step 42: loss = 8.5842 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 43: loss = 7.8518 (0.364 sec/step)\n",
      "I1128 20:56:13.230996 14512 learning.py:512] global step 43: loss = 7.8518 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 44: loss = 8.2211 (0.369 sec/step)\n",
      "I1128 20:56:13.602003 14512 learning.py:512] global step 44: loss = 8.2211 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 45: loss = 7.2365 (0.360 sec/step)\n",
      "I1128 20:56:13.963037 14512 learning.py:512] global step 45: loss = 7.2365 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 46: loss = 6.9535 (0.372 sec/step)\n",
      "I1128 20:56:14.336049 14512 learning.py:512] global step 46: loss = 6.9535 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 47: loss = 8.1859 (0.371 sec/step)\n",
      "I1128 20:56:14.707057 14512 learning.py:512] global step 47: loss = 8.1859 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 48: loss = 6.9594 (0.361 sec/step)\n",
      "I1128 20:56:15.069081 14512 learning.py:512] global step 48: loss = 6.9594 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 49: loss = 8.0039 (0.367 sec/step)\n",
      "I1128 20:56:15.437135 14512 learning.py:512] global step 49: loss = 8.0039 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 50: loss = 6.5131 (0.366 sec/step)\n",
      "I1128 20:56:15.805133 14512 learning.py:512] global step 50: loss = 6.5131 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 51: loss = 6.5250 (0.364 sec/step)\n",
      "I1128 20:56:16.169165 14512 learning.py:512] global step 51: loss = 6.5250 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 52: loss = 7.9287 (0.363 sec/step)\n",
      "I1128 20:56:16.534176 14512 learning.py:512] global step 52: loss = 7.9287 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 53: loss = 7.6138 (0.367 sec/step)\n",
      "I1128 20:56:16.903174 14512 learning.py:512] global step 53: loss = 7.6138 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 54: loss = 6.8845 (0.358 sec/step)\n",
      "I1128 20:56:17.262215 14512 learning.py:512] global step 54: loss = 6.8845 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 55: loss = 7.6842 (0.361 sec/step)\n",
      "I1128 20:56:17.624247 14512 learning.py:512] global step 55: loss = 7.6842 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 56: loss = 6.6832 (0.359 sec/step)\n",
      "I1128 20:56:17.985307 14512 learning.py:512] global step 56: loss = 6.6832 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 57: loss = 7.0850 (0.361 sec/step)\n",
      "I1128 20:56:18.348310 14512 learning.py:512] global step 57: loss = 7.0850 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 58: loss = 7.1378 (0.366 sec/step)\n",
      "I1128 20:56:18.716336 14512 learning.py:512] global step 58: loss = 7.1378 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 59: loss = 7.1007 (0.366 sec/step)\n",
      "I1128 20:56:19.083344 14512 learning.py:512] global step 59: loss = 7.1007 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 60: loss = 6.4985 (0.370 sec/step)\n",
      "I1128 20:56:19.454352 14512 learning.py:512] global step 60: loss = 6.4985 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 61: loss = 6.7641 (0.372 sec/step)\n",
      "I1128 20:56:19.828387 14512 learning.py:512] global step 61: loss = 6.7641 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 62: loss = 6.7689 (0.370 sec/step)\n",
      "I1128 20:56:20.199387 14512 learning.py:512] global step 62: loss = 6.7689 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 63: loss = 7.8823 (0.365 sec/step)\n",
      "I1128 20:56:20.566398 14512 learning.py:512] global step 63: loss = 7.8823 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 64: loss = 6.8906 (0.360 sec/step)\n",
      "I1128 20:56:20.927142 14512 learning.py:512] global step 64: loss = 6.8906 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 65: loss = 7.1956 (0.362 sec/step)\n",
      "I1128 20:56:21.290171 14512 learning.py:512] global step 65: loss = 7.1956 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 66: loss = 5.7908 (0.373 sec/step)\n",
      "I1128 20:56:21.665198 14512 learning.py:512] global step 66: loss = 5.7908 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 67: loss = 6.6407 (0.373 sec/step)\n",
      "I1128 20:56:22.040192 14512 learning.py:512] global step 67: loss = 6.6407 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 68: loss = 6.9697 (0.352 sec/step)\n",
      "I1128 20:56:22.392239 14512 learning.py:512] global step 68: loss = 6.9697 (0.352 sec/step)\n",
      "INFO:tensorflow:global step 69: loss = 5.6207 (0.366 sec/step)\n",
      "I1128 20:56:22.759293 14512 learning.py:512] global step 69: loss = 5.6207 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 70: loss = 6.2220 (0.365 sec/step)\n",
      "I1128 20:56:23.126260 14512 learning.py:512] global step 70: loss = 6.2220 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 71: loss = 6.4733 (0.360 sec/step)\n",
      "I1128 20:56:23.487671 14512 learning.py:512] global step 71: loss = 6.4733 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 72: loss = 6.0948 (0.371 sec/step)\n",
      "I1128 20:56:23.860647 14512 learning.py:512] global step 72: loss = 6.0948 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 73: loss = 6.2339 (0.361 sec/step)\n",
      "I1128 20:56:24.222295 14512 learning.py:512] global step 73: loss = 6.2339 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 74: loss = 7.8790 (0.367 sec/step)\n",
      "I1128 20:56:24.590310 14512 learning.py:512] global step 74: loss = 7.8790 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 75: loss = 7.8560 (0.357 sec/step)\n",
      "I1128 20:56:24.948353 14512 learning.py:512] global step 75: loss = 7.8560 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 76: loss = 6.3536 (0.367 sec/step)\n",
      "I1128 20:56:25.317368 14512 learning.py:512] global step 76: loss = 6.3536 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 77: loss = 6.3714 (0.364 sec/step)\n",
      "I1128 20:56:25.682390 14512 learning.py:512] global step 77: loss = 6.3714 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 78: loss = 6.1787 (0.359 sec/step)\n",
      "I1128 20:56:26.043432 14512 learning.py:512] global step 78: loss = 6.1787 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 79: loss = 6.0891 (0.370 sec/step)\n",
      "I1128 20:56:26.414433 14512 learning.py:512] global step 79: loss = 6.0891 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 80: loss = 5.6705 (0.358 sec/step)\n",
      "I1128 20:56:26.773486 14512 learning.py:512] global step 80: loss = 5.6705 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 81: loss = 5.9707 (0.365 sec/step)\n",
      "I1128 20:56:27.138495 14512 learning.py:512] global step 81: loss = 5.9707 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 82: loss = 6.4143 (0.370 sec/step)\n",
      "I1128 20:56:27.509504 14512 learning.py:512] global step 82: loss = 6.4143 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 83: loss = 6.8428 (0.370 sec/step)\n",
      "I1128 20:56:27.880514 14512 learning.py:512] global step 83: loss = 6.8428 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 84: loss = 5.9190 (0.363 sec/step)\n",
      "I1128 20:56:28.245554 14512 learning.py:512] global step 84: loss = 5.9190 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 85: loss = 5.8521 (0.362 sec/step)\n",
      "I1128 20:56:28.608572 14512 learning.py:512] global step 85: loss = 5.8521 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 86: loss = 5.9104 (0.359 sec/step)\n",
      "I1128 20:56:28.969598 14512 learning.py:512] global step 86: loss = 5.9104 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 87: loss = 5.8119 (0.363 sec/step)\n",
      "I1128 20:56:29.334643 14512 learning.py:512] global step 87: loss = 5.8119 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 88: loss = 5.7088 (0.361 sec/step)\n",
      "I1128 20:56:29.696655 14512 learning.py:512] global step 88: loss = 5.7088 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 89: loss = 5.3936 (0.367 sec/step)\n",
      "I1128 20:56:30.064674 14512 learning.py:512] global step 89: loss = 5.3936 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 90: loss = 5.1588 (0.359 sec/step)\n",
      "I1128 20:56:30.425725 14512 learning.py:512] global step 90: loss = 5.1588 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 91: loss = 5.4332 (0.364 sec/step)\n",
      "I1128 20:56:30.790758 14512 learning.py:512] global step 91: loss = 5.4332 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 92: loss = 6.1197 (0.362 sec/step)\n",
      "I1128 20:56:31.154770 14512 learning.py:512] global step 92: loss = 6.1197 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 93: loss = 5.8670 (0.357 sec/step)\n",
      "I1128 20:56:31.512823 14512 learning.py:512] global step 93: loss = 5.8670 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 94: loss = 7.7113 (0.366 sec/step)\n",
      "I1128 20:56:31.880812 14512 learning.py:512] global step 94: loss = 7.7113 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 95: loss = 5.8491 (0.366 sec/step)\n",
      "I1128 20:56:32.247839 14512 learning.py:512] global step 95: loss = 5.8491 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 96: loss = 5.4872 (0.369 sec/step)\n",
      "I1128 20:56:32.618862 14512 learning.py:512] global step 96: loss = 5.4872 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 97: loss = 5.5588 (0.362 sec/step)\n",
      "I1128 20:56:32.980871 14512 learning.py:512] global step 97: loss = 5.5588 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 98: loss = 5.4832 (0.367 sec/step)\n",
      "I1128 20:56:33.349743 14512 learning.py:512] global step 98: loss = 5.4832 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 99: loss = 6.8900 (0.363 sec/step)\n",
      "I1128 20:56:33.713791 14512 learning.py:512] global step 99: loss = 6.8900 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 100: loss = 6.7519 (0.360 sec/step)\n",
      "I1128 20:56:34.075873 14512 learning.py:512] global step 100: loss = 6.7519 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 101: loss = 5.5851 (0.354 sec/step)\n",
      "I1128 20:56:34.430918 14512 learning.py:512] global step 101: loss = 5.5851 (0.354 sec/step)\n",
      "INFO:tensorflow:global step 102: loss = 6.0871 (0.365 sec/step)\n",
      "I1128 20:56:34.797927 14512 learning.py:512] global step 102: loss = 6.0871 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 103: loss = 5.3309 (0.364 sec/step)\n",
      "I1128 20:56:35.162952 14512 learning.py:512] global step 103: loss = 5.3309 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 104: loss = 6.6046 (0.360 sec/step)\n",
      "I1128 20:56:35.524984 14512 learning.py:512] global step 104: loss = 6.6046 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 105: loss = 5.9260 (0.370 sec/step)\n",
      "I1128 20:56:35.894993 14512 learning.py:512] global step 105: loss = 5.9260 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 106: loss = 5.6850 (0.366 sec/step)\n",
      "I1128 20:56:36.262012 14512 learning.py:512] global step 106: loss = 5.6850 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 107: loss = 6.0805 (0.370 sec/step)\n",
      "I1128 20:56:36.634023 14512 learning.py:512] global step 107: loss = 6.0805 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 108: loss = 5.3785 (0.369 sec/step)\n",
      "I1128 20:56:37.005026 14512 learning.py:512] global step 108: loss = 5.3785 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 109: loss = 7.0421 (0.376 sec/step)\n",
      "I1128 20:56:37.382892 14512 learning.py:512] global step 109: loss = 7.0421 (0.376 sec/step)\n",
      "INFO:tensorflow:global step 110: loss = 6.5216 (0.365 sec/step)\n",
      "I1128 20:56:37.749914 14512 learning.py:512] global step 110: loss = 6.5216 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 111: loss = 4.7201 (0.373 sec/step)\n",
      "I1128 20:56:38.123914 14512 learning.py:512] global step 111: loss = 4.7201 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 112: loss = 4.9313 (0.371 sec/step)\n",
      "I1128 20:56:38.496916 14512 learning.py:512] global step 112: loss = 4.9313 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 113: loss = 5.7016 (0.365 sec/step)\n",
      "I1128 20:56:38.863934 14512 learning.py:512] global step 113: loss = 5.7016 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 114: loss = 5.1420 (0.370 sec/step)\n",
      "I1128 20:56:39.233943 14512 learning.py:512] global step 114: loss = 5.1420 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 115: loss = 5.1911 (0.356 sec/step)\n",
      "I1128 20:56:39.591989 14512 learning.py:512] global step 115: loss = 5.1911 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 116: loss = 5.4642 (0.370 sec/step)\n",
      "I1128 20:56:39.961998 14512 learning.py:512] global step 116: loss = 5.4642 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 117: loss = 5.2880 (0.363 sec/step)\n",
      "I1128 20:56:40.327021 14512 learning.py:512] global step 117: loss = 5.2880 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 118: loss = 5.3269 (0.360 sec/step)\n",
      "I1128 20:56:40.688055 14512 learning.py:512] global step 118: loss = 5.3269 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 119: loss = 5.4291 (0.363 sec/step)\n",
      "I1128 20:56:41.051085 14512 learning.py:512] global step 119: loss = 5.4291 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 120: loss = 4.9620 (0.373 sec/step)\n",
      "I1128 20:56:41.426087 14512 learning.py:512] global step 120: loss = 4.9620 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 121: loss = 4.9485 (0.376 sec/step)\n",
      "I1128 20:56:41.803588 14512 learning.py:512] global step 121: loss = 4.9485 (0.376 sec/step)\n",
      "INFO:tensorflow:global step 122: loss = 4.8879 (0.369 sec/step)\n",
      "I1128 20:56:42.174595 14512 learning.py:512] global step 122: loss = 4.8879 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 123: loss = 5.1741 (0.366 sec/step)\n",
      "I1128 20:56:42.541613 14512 learning.py:512] global step 123: loss = 5.1741 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 124: loss = 5.6806 (0.359 sec/step)\n",
      "I1128 20:56:42.901683 14512 learning.py:512] global step 124: loss = 5.6806 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 125: loss = 5.6090 (0.367 sec/step)\n",
      "I1128 20:56:43.269666 14512 learning.py:512] global step 125: loss = 5.6090 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 126: loss = 5.1936 (0.370 sec/step)\n",
      "I1128 20:56:43.641672 14512 learning.py:512] global step 126: loss = 5.1936 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 127: loss = 5.4524 (0.364 sec/step)\n",
      "I1128 20:56:44.006722 14512 learning.py:512] global step 127: loss = 5.4524 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 128: loss = 4.6635 (0.367 sec/step)\n",
      "I1128 20:56:44.375708 14512 learning.py:512] global step 128: loss = 4.6635 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 129: loss = 5.0928 (0.363 sec/step)\n",
      "I1128 20:56:44.738739 14512 learning.py:512] global step 129: loss = 5.0928 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 130: loss = 3.7579 (0.363 sec/step)\n",
      "I1128 20:56:45.103788 14512 learning.py:512] global step 130: loss = 3.7579 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 131: loss = 4.6726 (0.362 sec/step)\n",
      "I1128 20:56:45.466790 14512 learning.py:512] global step 131: loss = 4.6726 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 132: loss = 6.0349 (0.366 sec/step)\n",
      "I1128 20:56:45.834807 14512 learning.py:512] global step 132: loss = 6.0349 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 133: loss = 5.8235 (0.366 sec/step)\n",
      "I1128 20:56:46.202822 14512 learning.py:512] global step 133: loss = 5.8235 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 134: loss = 5.0845 (0.362 sec/step)\n",
      "I1128 20:56:46.566858 14512 learning.py:512] global step 134: loss = 5.0845 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 135: loss = 4.7868 (0.367 sec/step)\n",
      "I1128 20:56:46.934865 14512 learning.py:512] global step 135: loss = 4.7868 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 136: loss = 4.8195 (0.364 sec/step)\n",
      "I1128 20:56:47.300912 14512 learning.py:512] global step 136: loss = 4.8195 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 137: loss = 5.2073 (0.352 sec/step)\n",
      "I1128 20:56:47.654958 14512 learning.py:512] global step 137: loss = 5.2073 (0.352 sec/step)\n",
      "INFO:tensorflow:global step 138: loss = 5.1809 (0.361 sec/step)\n",
      "I1128 20:56:48.016972 14512 learning.py:512] global step 138: loss = 5.1809 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 139: loss = 4.9023 (0.357 sec/step)\n",
      "I1128 20:56:48.375013 14512 learning.py:512] global step 139: loss = 4.9023 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 140: loss = 4.2144 (0.357 sec/step)\n",
      "I1128 20:56:48.733087 14512 learning.py:512] global step 140: loss = 4.2144 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 141: loss = 4.9112 (0.365 sec/step)\n",
      "I1128 20:56:49.099105 14512 learning.py:512] global step 141: loss = 4.9112 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 142: loss = 4.3125 (0.362 sec/step)\n",
      "I1128 20:56:49.462110 14512 learning.py:512] global step 142: loss = 4.3125 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 143: loss = 5.3296 (0.362 sec/step)\n",
      "I1128 20:56:49.826149 14512 learning.py:512] global step 143: loss = 5.3296 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 144: loss = 4.9470 (0.375 sec/step)\n",
      "I1128 20:56:50.203080 14512 learning.py:512] global step 144: loss = 4.9470 (0.375 sec/step)\n",
      "INFO:tensorflow:global step 145: loss = 5.5197 (0.359 sec/step)\n",
      "I1128 20:56:50.562114 14512 learning.py:512] global step 145: loss = 5.5197 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 146: loss = 5.3667 (0.359 sec/step)\n",
      "I1128 20:56:50.923163 14512 learning.py:512] global step 146: loss = 5.3667 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 147: loss = 7.0855 (0.372 sec/step)\n",
      "I1128 20:56:51.297147 14512 learning.py:512] global step 147: loss = 7.0855 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 148: loss = 5.0653 (0.370 sec/step)\n",
      "I1128 20:56:51.667184 14512 learning.py:512] global step 148: loss = 5.0653 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 149: loss = 4.1739 (0.365 sec/step)\n",
      "I1128 20:56:52.034204 14512 learning.py:512] global step 149: loss = 4.1739 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 150: loss = 4.2180 (0.366 sec/step)\n",
      "I1128 20:56:52.401208 14512 learning.py:512] global step 150: loss = 4.2180 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 151: loss = 4.8788 (0.369 sec/step)\n",
      "I1128 20:56:52.771232 14512 learning.py:512] global step 151: loss = 4.8788 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 152: loss = 5.4624 (0.359 sec/step)\n",
      "I1128 20:56:53.132241 14512 learning.py:512] global step 152: loss = 5.4624 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 153: loss = 5.0499 (0.365 sec/step)\n",
      "I1128 20:56:53.498262 14512 learning.py:512] global step 153: loss = 5.0499 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 154: loss = 4.0456 (0.365 sec/step)\n",
      "I1128 20:56:53.865294 14512 learning.py:512] global step 154: loss = 4.0456 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 155: loss = 4.9270 (0.364 sec/step)\n",
      "I1128 20:56:54.230304 14512 learning.py:512] global step 155: loss = 4.9270 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 156: loss = 5.0919 (0.367 sec/step)\n",
      "I1128 20:56:54.598348 14512 learning.py:512] global step 156: loss = 5.0919 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 157: loss = 5.4960 (0.356 sec/step)\n",
      "I1128 20:56:54.955365 14512 learning.py:512] global step 157: loss = 5.4960 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 158: loss = 5.2870 (0.359 sec/step)\n",
      "I1128 20:56:55.316408 14512 learning.py:512] global step 158: loss = 5.2870 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 159: loss = 4.7459 (0.370 sec/step)\n",
      "I1128 20:56:55.688421 14512 learning.py:512] global step 159: loss = 4.7459 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 160: loss = 4.8735 (0.362 sec/step)\n",
      "I1128 20:56:56.051459 14512 learning.py:512] global step 160: loss = 4.8735 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 161: loss = 4.6758 (0.362 sec/step)\n",
      "I1128 20:56:56.414648 14512 learning.py:512] global step 161: loss = 4.6758 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 162: loss = 4.3435 (0.361 sec/step)\n",
      "I1128 20:56:56.777684 14512 learning.py:512] global step 162: loss = 4.3435 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 163: loss = 4.9651 (0.353 sec/step)\n",
      "I1128 20:56:57.132098 14512 learning.py:512] global step 163: loss = 4.9651 (0.353 sec/step)\n",
      "INFO:tensorflow:global step 164: loss = 4.8348 (0.359 sec/step)\n",
      "I1128 20:56:57.492138 14512 learning.py:512] global step 164: loss = 4.8348 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 165: loss = 5.1929 (0.367 sec/step)\n",
      "I1128 20:56:57.861176 14512 learning.py:512] global step 165: loss = 5.1929 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 166: loss = 4.0010 (0.357 sec/step)\n",
      "I1128 20:56:58.220209 14512 learning.py:512] global step 166: loss = 4.0010 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 167: loss = 4.7238 (0.363 sec/step)\n",
      "I1128 20:56:58.585226 14512 learning.py:512] global step 167: loss = 4.7238 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 168: loss = 4.0267 (0.360 sec/step)\n",
      "I1128 20:56:58.946262 14512 learning.py:512] global step 168: loss = 4.0267 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 169: loss = 6.5989 (0.370 sec/step)\n",
      "I1128 20:56:59.316260 14512 learning.py:512] global step 169: loss = 6.5989 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 170: loss = 4.4998 (0.358 sec/step)\n",
      "I1128 20:56:59.675298 14512 learning.py:512] global step 170: loss = 4.4998 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 171: loss = 4.5186 (0.358 sec/step)\n",
      "I1128 20:57:00.034339 14512 learning.py:512] global step 171: loss = 4.5186 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 172: loss = 3.9341 (0.352 sec/step)\n",
      "I1128 20:57:00.388401 14512 learning.py:512] global step 172: loss = 3.9341 (0.352 sec/step)\n",
      "INFO:tensorflow:global step 173: loss = 3.9652 (0.363 sec/step)\n",
      "I1128 20:57:00.752418 14512 learning.py:512] global step 173: loss = 3.9652 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 174: loss = 4.4441 (0.363 sec/step)\n",
      "I1128 20:57:01.116445 14512 learning.py:512] global step 174: loss = 4.4441 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 175: loss = 5.0380 (0.371 sec/step)\n",
      "I1128 20:57:01.488451 14512 learning.py:512] global step 175: loss = 5.0380 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 176: loss = 4.3673 (0.365 sec/step)\n",
      "I1128 20:57:01.855489 14512 learning.py:512] global step 176: loss = 4.3673 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 177: loss = 4.4132 (0.362 sec/step)\n",
      "I1128 20:57:02.218499 14512 learning.py:512] global step 177: loss = 4.4132 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 178: loss = 4.3460 (0.367 sec/step)\n",
      "I1128 20:57:02.587511 14512 learning.py:512] global step 178: loss = 4.3460 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 179: loss = 3.9011 (0.357 sec/step)\n",
      "I1128 20:57:02.946552 14512 learning.py:512] global step 179: loss = 3.9011 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 180: loss = 4.3539 (0.363 sec/step)\n",
      "I1128 20:57:03.311573 14512 learning.py:512] global step 180: loss = 4.3539 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 181: loss = 5.3190 (0.359 sec/step)\n",
      "I1128 20:57:03.671611 14512 learning.py:512] global step 181: loss = 5.3190 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 182: loss = 3.8437 (0.358 sec/step)\n",
      "I1128 20:57:04.031649 14512 learning.py:512] global step 182: loss = 3.8437 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 183: loss = 4.1919 (0.360 sec/step)\n",
      "I1128 20:57:04.393682 14512 learning.py:512] global step 183: loss = 4.1919 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 184: loss = 3.3507 (0.372 sec/step)\n",
      "I1128 20:57:04.768101 14512 learning.py:512] global step 184: loss = 3.3507 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 185: loss = 4.1185 (0.370 sec/step)\n",
      "I1128 20:57:05.139113 14512 learning.py:512] global step 185: loss = 4.1185 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 186: loss = 4.8084 (0.381 sec/step)\n",
      "I1128 20:57:05.521090 14512 learning.py:512] global step 186: loss = 4.8084 (0.381 sec/step)\n",
      "INFO:tensorflow:global step 187: loss = 4.5716 (0.362 sec/step)\n",
      "I1128 20:57:05.884119 14512 learning.py:512] global step 187: loss = 4.5716 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 188: loss = 4.2228 (0.367 sec/step)\n",
      "I1128 20:57:06.252148 14512 learning.py:512] global step 188: loss = 4.2228 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 189: loss = 4.2225 (0.358 sec/step)\n",
      "I1128 20:57:06.610178 14512 learning.py:512] global step 189: loss = 4.2225 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 190: loss = 4.6155 (0.364 sec/step)\n",
      "I1128 20:57:06.976223 14512 learning.py:512] global step 190: loss = 4.6155 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 191: loss = 3.7898 (0.364 sec/step)\n",
      "I1128 20:57:07.342224 14512 learning.py:512] global step 191: loss = 3.7898 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 192: loss = 4.5999 (0.357 sec/step)\n",
      "I1128 20:57:07.701269 14512 learning.py:512] global step 192: loss = 4.5999 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 193: loss = 4.3391 (0.360 sec/step)\n",
      "I1128 20:57:08.063292 14512 learning.py:512] global step 193: loss = 4.3391 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 194: loss = 4.1771 (0.377 sec/step)\n",
      "I1128 20:57:08.442277 14512 learning.py:512] global step 194: loss = 4.1771 (0.377 sec/step)\n",
      "INFO:tensorflow:global step 195: loss = 4.4231 (0.359 sec/step)\n",
      "I1128 20:57:08.802341 14512 learning.py:512] global step 195: loss = 4.4231 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 196: loss = 3.6344 (0.367 sec/step)\n",
      "I1128 20:57:09.171342 14512 learning.py:512] global step 196: loss = 3.6344 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 197: loss = 4.0575 (0.368 sec/step)\n",
      "I1128 20:57:09.541339 14512 learning.py:512] global step 197: loss = 4.0575 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 198: loss = 3.5998 (0.353 sec/step)\n",
      "I1128 20:57:09.896389 14512 learning.py:512] global step 198: loss = 3.5998 (0.353 sec/step)\n",
      "INFO:tensorflow:global step 199: loss = 3.7277 (0.364 sec/step)\n",
      "I1128 20:57:10.261412 14512 learning.py:512] global step 199: loss = 3.7277 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 200: loss = 4.1857 (0.363 sec/step)\n",
      "I1128 20:57:10.625439 14512 learning.py:512] global step 200: loss = 4.1857 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 201: loss = 5.8551 (0.365 sec/step)\n",
      "I1128 20:57:10.992457 14512 learning.py:512] global step 201: loss = 5.8551 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 202: loss = 4.9990 (0.361 sec/step)\n",
      "I1128 20:57:11.354501 14512 learning.py:512] global step 202: loss = 4.9990 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 203: loss = 4.7898 (0.358 sec/step)\n",
      "I1128 20:57:11.713535 14512 learning.py:512] global step 203: loss = 4.7898 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 204: loss = 4.0494 (0.359 sec/step)\n",
      "I1128 20:57:12.073781 14512 learning.py:512] global step 204: loss = 4.0494 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 205: loss = 4.7435 (0.358 sec/step)\n",
      "I1128 20:57:12.432832 14512 learning.py:512] global step 205: loss = 4.7435 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 206: loss = 4.3795 (0.362 sec/step)\n",
      "I1128 20:57:12.795853 14512 learning.py:512] global step 206: loss = 4.3795 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 207: loss = 3.7361 (0.371 sec/step)\n",
      "I1128 20:57:13.168855 14512 learning.py:512] global step 207: loss = 3.7361 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 208: loss = 4.9103 (0.377 sec/step)\n",
      "I1128 20:57:13.547855 14512 learning.py:512] global step 208: loss = 4.9103 (0.377 sec/step)\n",
      "INFO:tensorflow:global step 209: loss = 4.1518 (0.369 sec/step)\n",
      "I1128 20:57:13.917866 14512 learning.py:512] global step 209: loss = 4.1518 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 210: loss = 3.5242 (0.367 sec/step)\n",
      "I1128 20:57:14.286864 14512 learning.py:512] global step 210: loss = 3.5242 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 211: loss = 3.8183 (0.357 sec/step)\n",
      "I1128 20:57:14.645912 14512 learning.py:512] global step 211: loss = 3.8183 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 212: loss = 4.4651 (0.357 sec/step)\n",
      "I1128 20:57:15.003967 14512 learning.py:512] global step 212: loss = 4.4651 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 213: loss = 3.3973 (0.383 sec/step)\n",
      "I1128 20:57:15.387921 14512 learning.py:512] global step 213: loss = 3.3973 (0.383 sec/step)\n",
      "INFO:tensorflow:global step 214: loss = 4.3983 (0.370 sec/step)\n",
      "I1128 20:57:15.759953 14512 learning.py:512] global step 214: loss = 4.3983 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 215: loss = 4.0267 (0.356 sec/step)\n",
      "I1128 20:57:16.116997 14512 learning.py:512] global step 215: loss = 4.0267 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 216: loss = 3.9723 (0.360 sec/step)\n",
      "I1128 20:57:16.479000 14512 learning.py:512] global step 216: loss = 3.9723 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 217: loss = 3.4259 (0.361 sec/step)\n",
      "I1128 20:57:16.842039 14512 learning.py:512] global step 217: loss = 3.4259 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 218: loss = 3.8660 (0.360 sec/step)\n",
      "I1128 20:57:17.203858 14512 learning.py:512] global step 218: loss = 3.8660 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 219: loss = 3.0614 (0.366 sec/step)\n",
      "I1128 20:57:17.571856 14512 learning.py:512] global step 219: loss = 3.0614 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 220: loss = 5.6792 (0.362 sec/step)\n",
      "I1128 20:57:17.935883 14512 learning.py:512] global step 220: loss = 5.6792 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 221: loss = 4.7647 (0.365 sec/step)\n",
      "I1128 20:57:18.300933 14512 learning.py:512] global step 221: loss = 4.7647 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 222: loss = 3.6129 (0.363 sec/step)\n",
      "I1128 20:57:18.665931 14512 learning.py:512] global step 222: loss = 3.6129 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 223: loss = 3.2751 (0.373 sec/step)\n",
      "I1128 20:57:19.039930 14512 learning.py:512] global step 223: loss = 3.2751 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 224: loss = 4.2292 (0.371 sec/step)\n",
      "I1128 20:57:19.413836 14512 learning.py:512] global step 224: loss = 4.2292 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 225: loss = 2.6402 (0.384 sec/step)\n",
      "I1128 20:57:19.799790 14512 learning.py:512] global step 225: loss = 2.6402 (0.384 sec/step)\n",
      "INFO:tensorflow:global step 226: loss = 2.6468 (0.368 sec/step)\n",
      "I1128 20:57:20.168802 14512 learning.py:512] global step 226: loss = 2.6468 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 227: loss = 4.2727 (0.364 sec/step)\n",
      "I1128 20:57:20.534824 14512 learning.py:512] global step 227: loss = 4.2727 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 228: loss = 3.3930 (0.354 sec/step)\n",
      "I1128 20:57:20.889878 14512 learning.py:512] global step 228: loss = 3.3930 (0.354 sec/step)\n",
      "INFO:tensorflow:global step 229: loss = 3.3891 (0.370 sec/step)\n",
      "I1128 20:57:21.261934 14512 learning.py:512] global step 229: loss = 3.3891 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 230: loss = 2.9191 (0.360 sec/step)\n",
      "I1128 20:57:21.623912 14512 learning.py:512] global step 230: loss = 2.9191 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 231: loss = 3.0877 (0.368 sec/step)\n",
      "I1128 20:57:21.991926 14512 learning.py:512] global step 231: loss = 3.0877 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 232: loss = 3.4188 (0.368 sec/step)\n",
      "I1128 20:57:22.360940 14512 learning.py:512] global step 232: loss = 3.4188 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 233: loss = 4.0720 (0.359 sec/step)\n",
      "I1128 20:57:22.721978 14512 learning.py:512] global step 233: loss = 4.0720 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 234: loss = 3.5750 (0.365 sec/step)\n",
      "I1128 20:57:23.087996 14512 learning.py:512] global step 234: loss = 3.5750 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 235: loss = 3.5905 (0.370 sec/step)\n",
      "I1128 20:57:23.460001 14512 learning.py:512] global step 235: loss = 3.5905 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 236: loss = 2.7012 (0.362 sec/step)\n",
      "I1128 20:57:23.823030 14512 learning.py:512] global step 236: loss = 2.7012 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 237: loss = 3.5172 (0.365 sec/step)\n",
      "I1128 20:57:24.189761 14512 learning.py:512] global step 237: loss = 3.5172 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 238: loss = 5.0299 (0.359 sec/step)\n",
      "I1128 20:57:24.550807 14512 learning.py:512] global step 238: loss = 5.0299 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 239: loss = 3.6383 (0.361 sec/step)\n",
      "I1128 20:57:24.914127 14512 learning.py:512] global step 239: loss = 3.6383 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 240: loss = 3.6943 (0.361 sec/step)\n",
      "I1128 20:57:25.276162 14512 learning.py:512] global step 240: loss = 3.6943 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 241: loss = 2.9354 (0.359 sec/step)\n",
      "I1128 20:57:25.635228 14512 learning.py:512] global step 241: loss = 2.9354 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 242: loss = 4.9511 (0.366 sec/step)\n",
      "I1128 20:57:26.003232 14512 learning.py:512] global step 242: loss = 4.9511 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 243: loss = 3.1028 (0.365 sec/step)\n",
      "I1128 20:57:26.368255 14512 learning.py:512] global step 243: loss = 3.1028 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 244: loss = 3.8485 (0.365 sec/step)\n",
      "I1128 20:57:26.735191 14512 learning.py:512] global step 244: loss = 3.8485 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 245: loss = 3.6525 (0.370 sec/step)\n",
      "I1128 20:57:27.106850 14512 learning.py:512] global step 245: loss = 3.6525 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 246: loss = 3.8979 (0.363 sec/step)\n",
      "I1128 20:57:27.470884 14512 learning.py:512] global step 246: loss = 3.8979 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 247: loss = 3.2900 (0.362 sec/step)\n",
      "I1128 20:57:27.833907 14512 learning.py:512] global step 247: loss = 3.2900 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 248: loss = 3.3650 (0.369 sec/step)\n",
      "I1128 20:57:28.203930 14512 learning.py:512] global step 248: loss = 3.3650 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 249: loss = 3.3213 (0.357 sec/step)\n",
      "I1128 20:57:28.562804 14512 learning.py:512] global step 249: loss = 3.3213 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 250: loss = 3.8364 (0.365 sec/step)\n",
      "I1128 20:57:28.929822 14512 learning.py:512] global step 250: loss = 3.8364 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 251: loss = 4.7666 (0.362 sec/step)\n",
      "I1128 20:57:29.292862 14512 learning.py:512] global step 251: loss = 4.7666 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 252: loss = 4.6381 (0.358 sec/step)\n",
      "I1128 20:57:29.652404 14512 learning.py:512] global step 252: loss = 4.6381 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 253: loss = 4.4057 (0.362 sec/step)\n",
      "I1128 20:57:30.017427 14512 learning.py:512] global step 253: loss = 4.4057 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 254: loss = 4.3187 (0.356 sec/step)\n",
      "I1128 20:57:30.373477 14512 learning.py:512] global step 254: loss = 4.3187 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 255: loss = 3.9126 (0.366 sec/step)\n",
      "I1128 20:57:30.741514 14512 learning.py:512] global step 255: loss = 3.9126 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 256: loss = 4.4963 (0.356 sec/step)\n",
      "I1128 20:57:31.098537 14512 learning.py:512] global step 256: loss = 4.4963 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 257: loss = 3.2841 (0.362 sec/step)\n",
      "I1128 20:57:31.462564 14512 learning.py:512] global step 257: loss = 3.2841 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 258: loss = 4.0946 (0.371 sec/step)\n",
      "I1128 20:57:31.835565 14512 learning.py:512] global step 258: loss = 4.0946 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 259: loss = 3.5444 (0.369 sec/step)\n",
      "I1128 20:57:32.205576 14512 learning.py:512] global step 259: loss = 3.5444 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 260: loss = 3.5162 (0.362 sec/step)\n",
      "I1128 20:57:32.567654 14512 learning.py:512] global step 260: loss = 3.5162 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 261: loss = 3.5072 (0.359 sec/step)\n",
      "I1128 20:57:32.928690 14512 learning.py:512] global step 261: loss = 3.5072 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 262: loss = 5.1183 (0.360 sec/step)\n",
      "I1128 20:57:33.290678 14512 learning.py:512] global step 262: loss = 5.1183 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 263: loss = 4.2433 (0.369 sec/step)\n",
      "I1128 20:57:33.661695 14512 learning.py:512] global step 263: loss = 4.2433 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 264: loss = 2.9414 (0.367 sec/step)\n",
      "I1128 20:57:34.030722 14512 learning.py:512] global step 264: loss = 2.9414 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 265: loss = 4.4535 (0.369 sec/step)\n",
      "I1128 20:57:34.400732 14512 learning.py:512] global step 265: loss = 4.4535 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 266: loss = 3.6593 (0.365 sec/step)\n",
      "I1128 20:57:34.767723 14512 learning.py:512] global step 266: loss = 3.6593 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 267: loss = 4.5539 (0.365 sec/step)\n",
      "I1128 20:57:35.134742 14512 learning.py:512] global step 267: loss = 4.5539 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 268: loss = 3.1562 (0.370 sec/step)\n",
      "I1128 20:57:35.506748 14512 learning.py:512] global step 268: loss = 3.1562 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 269: loss = 3.1227 (0.370 sec/step)\n",
      "I1128 20:57:35.877761 14512 learning.py:512] global step 269: loss = 3.1227 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 270: loss = 2.8790 (0.359 sec/step)\n",
      "I1128 20:57:36.237791 14512 learning.py:512] global step 270: loss = 2.8790 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 271: loss = 3.0479 (0.366 sec/step)\n",
      "I1128 20:57:36.604812 14512 learning.py:512] global step 271: loss = 3.0479 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 272: loss = 3.5101 (0.350 sec/step)\n",
      "I1128 20:57:36.955873 14512 learning.py:512] global step 272: loss = 3.5101 (0.350 sec/step)\n",
      "INFO:tensorflow:global step 273: loss = 3.2154 (0.359 sec/step)\n",
      "I1128 20:57:37.316926 14512 learning.py:512] global step 273: loss = 3.2154 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 274: loss = 3.2791 (0.357 sec/step)\n",
      "I1128 20:57:37.675960 14512 learning.py:512] global step 274: loss = 3.2791 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 275: loss = 4.2018 (0.367 sec/step)\n",
      "I1128 20:57:38.044909 14512 learning.py:512] global step 275: loss = 4.2018 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 276: loss = 3.8625 (0.363 sec/step)\n",
      "I1128 20:57:38.409384 14512 learning.py:512] global step 276: loss = 3.8625 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 277: loss = 3.4056 (0.371 sec/step)\n",
      "I1128 20:57:38.781406 14512 learning.py:512] global step 277: loss = 3.4056 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 278: loss = 3.9671 (0.371 sec/step)\n",
      "I1128 20:57:39.154392 14512 learning.py:512] global step 278: loss = 3.9671 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 279: loss = 4.0759 (0.359 sec/step)\n",
      "I1128 20:57:39.513431 14512 learning.py:512] global step 279: loss = 4.0759 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 280: loss = 3.4103 (0.370 sec/step)\n",
      "I1128 20:57:39.885435 14512 learning.py:512] global step 280: loss = 3.4103 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 281: loss = 3.7283 (0.357 sec/step)\n",
      "I1128 20:57:40.244055 14512 learning.py:512] global step 281: loss = 3.7283 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 282: loss = 3.5023 (0.364 sec/step)\n",
      "I1128 20:57:40.609082 14512 learning.py:512] global step 282: loss = 3.5023 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 283: loss = 3.0959 (0.364 sec/step)\n",
      "I1128 20:57:40.974105 14512 learning.py:512] global step 283: loss = 3.0959 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 284: loss = 3.7071 (0.367 sec/step)\n",
      "I1128 20:57:41.341124 14512 learning.py:512] global step 284: loss = 3.7071 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 285: loss = 3.4670 (0.360 sec/step)\n",
      "I1128 20:57:41.703162 14512 learning.py:512] global step 285: loss = 3.4670 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 286: loss = 2.2341 (0.362 sec/step)\n",
      "I1128 20:57:42.066184 14512 learning.py:512] global step 286: loss = 2.2341 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 287: loss = 3.5382 (0.372 sec/step)\n",
      "I1128 20:57:42.440185 14512 learning.py:512] global step 287: loss = 3.5382 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 288: loss = 3.8913 (0.358 sec/step)\n",
      "I1128 20:57:42.799224 14512 learning.py:512] global step 288: loss = 3.8913 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 289: loss = 3.4620 (0.360 sec/step)\n",
      "I1128 20:57:43.160259 14512 learning.py:512] global step 289: loss = 3.4620 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 290: loss = 3.3045 (0.370 sec/step)\n",
      "I1128 20:57:43.530268 14512 learning.py:512] global step 290: loss = 3.3045 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 291: loss = 3.2436 (0.366 sec/step)\n",
      "I1128 20:57:43.898286 14512 learning.py:512] global step 291: loss = 3.2436 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 292: loss = 3.7279 (0.359 sec/step)\n",
      "I1128 20:57:44.258322 14512 learning.py:512] global step 292: loss = 3.7279 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 293: loss = 3.7239 (0.369 sec/step)\n",
      "I1128 20:57:44.629343 14512 learning.py:512] global step 293: loss = 3.7239 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 294: loss = 2.8683 (0.359 sec/step)\n",
      "I1128 20:57:44.989366 14512 learning.py:512] global step 294: loss = 2.8683 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 295: loss = 3.6330 (0.375 sec/step)\n",
      "I1128 20:57:45.364364 14512 learning.py:512] global step 295: loss = 3.6330 (0.375 sec/step)\n",
      "INFO:tensorflow:global step 296: loss = 3.7993 (0.362 sec/step)\n",
      "I1128 20:57:45.728390 14512 learning.py:512] global step 296: loss = 3.7993 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 297: loss = 3.5502 (0.371 sec/step)\n",
      "I1128 20:57:46.100395 14512 learning.py:512] global step 297: loss = 3.5502 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 298: loss = 3.2652 (0.358 sec/step)\n",
      "I1128 20:57:46.460433 14512 learning.py:512] global step 298: loss = 3.2652 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 299: loss = 4.5427 (0.367 sec/step)\n",
      "I1128 20:57:46.829446 14512 learning.py:512] global step 299: loss = 4.5427 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 300: loss = 2.9002 (0.379 sec/step)\n",
      "I1128 20:57:47.209430 14512 learning.py:512] global step 300: loss = 2.9002 (0.379 sec/step)\n",
      "INFO:tensorflow:global step 301: loss = 3.5764 (0.367 sec/step)\n",
      "I1128 20:57:47.576447 14512 learning.py:512] global step 301: loss = 3.5764 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 302: loss = 3.8524 (0.371 sec/step)\n",
      "I1128 20:57:47.949900 14512 learning.py:512] global step 302: loss = 3.8524 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 303: loss = 2.5890 (0.365 sec/step)\n",
      "I1128 20:57:48.315892 14512 learning.py:512] global step 303: loss = 2.5890 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 304: loss = 3.5074 (0.366 sec/step)\n",
      "I1128 20:57:48.682937 14512 learning.py:512] global step 304: loss = 3.5074 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 305: loss = 2.8481 (0.363 sec/step)\n",
      "I1128 20:57:49.046936 14512 learning.py:512] global step 305: loss = 2.8481 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 306: loss = 3.4311 (0.360 sec/step)\n",
      "I1128 20:57:49.408995 14512 learning.py:512] global step 306: loss = 3.4311 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 307: loss = 3.6276 (0.367 sec/step)\n",
      "I1128 20:57:49.777983 14512 learning.py:512] global step 307: loss = 3.6276 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 308: loss = 2.3639 (0.363 sec/step)\n",
      "I1128 20:57:50.142008 14512 learning.py:512] global step 308: loss = 2.3639 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 309: loss = 3.8243 (0.363 sec/step)\n",
      "I1128 20:57:50.506035 14512 learning.py:512] global step 309: loss = 3.8243 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 310: loss = 2.5003 (0.376 sec/step)\n",
      "I1128 20:57:50.882029 14512 learning.py:512] global step 310: loss = 2.5003 (0.376 sec/step)\n",
      "INFO:tensorflow:global step 311: loss = 2.7752 (0.391 sec/step)\n",
      "I1128 20:57:51.274978 14512 learning.py:512] global step 311: loss = 2.7752 (0.391 sec/step)\n",
      "INFO:tensorflow:global step 312: loss = 3.3599 (0.373 sec/step)\n",
      "I1128 20:57:51.649975 14512 learning.py:512] global step 312: loss = 3.3599 (0.373 sec/step)\n",
      "INFO:tensorflow:global step 313: loss = 3.0354 (0.365 sec/step)\n",
      "I1128 20:57:52.014999 14512 learning.py:512] global step 313: loss = 3.0354 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 314: loss = 3.6130 (0.368 sec/step)\n",
      "I1128 20:57:52.385009 14512 learning.py:512] global step 314: loss = 3.6130 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 315: loss = 3.3808 (0.371 sec/step)\n",
      "I1128 20:57:52.756950 14512 learning.py:512] global step 315: loss = 3.3808 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 316: loss = 2.9427 (0.366 sec/step)\n",
      "I1128 20:57:53.122973 14512 learning.py:512] global step 316: loss = 2.9427 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 317: loss = 2.4772 (0.360 sec/step)\n",
      "I1128 20:57:53.485017 14512 learning.py:512] global step 317: loss = 2.4772 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 318: loss = 2.5665 (0.361 sec/step)\n",
      "I1128 20:57:53.847066 14512 learning.py:512] global step 318: loss = 2.5665 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 319: loss = 4.2216 (0.358 sec/step)\n",
      "I1128 20:57:54.206078 14512 learning.py:512] global step 319: loss = 4.2216 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 320: loss = 3.0540 (0.369 sec/step)\n",
      "I1128 20:57:54.591347 14512 learning.py:512] global step 320: loss = 3.0540 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 321: loss = 3.0761 (0.440 sec/step)\n",
      "I1128 20:57:55.033166 14512 learning.py:512] global step 321: loss = 3.0761 (0.440 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 321.\n",
      "I1128 20:57:55.163816 13864 supervisor.py:1050] Recording summary at step 321.\n",
      "INFO:tensorflow:global step 322: loss = 3.0779 (0.426 sec/step)\n",
      "I1128 20:57:55.460025 14512 learning.py:512] global step 322: loss = 3.0779 (0.426 sec/step)\n",
      "INFO:tensorflow:global step 323: loss = 3.2538 (0.360 sec/step)\n",
      "I1128 20:57:55.822057 14512 learning.py:512] global step 323: loss = 3.2538 (0.360 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 2.54762\n",
      "I1128 20:57:56.095325 14452 supervisor.py:1099] global_step/sec: 2.54762\n",
      "INFO:tensorflow:global step 324: loss = 3.9382 (0.367 sec/step)\n",
      "I1128 20:57:56.190097 14512 learning.py:512] global step 324: loss = 3.9382 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 325: loss = 2.8729 (0.356 sec/step)\n",
      "I1128 20:57:56.548140 14512 learning.py:512] global step 325: loss = 2.8729 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 326: loss = 2.5877 (0.367 sec/step)\n",
      "I1128 20:57:56.917138 14512 learning.py:512] global step 326: loss = 2.5877 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 327: loss = 3.8627 (0.361 sec/step)\n",
      "I1128 20:57:57.278162 14512 learning.py:512] global step 327: loss = 3.8627 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 328: loss = 2.8505 (0.353 sec/step)\n",
      "I1128 20:57:57.633212 14512 learning.py:512] global step 328: loss = 2.8505 (0.353 sec/step)\n",
      "INFO:tensorflow:global step 329: loss = 2.9021 (0.365 sec/step)\n",
      "I1128 20:57:57.999249 14512 learning.py:512] global step 329: loss = 2.9021 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 330: loss = 3.0893 (0.364 sec/step)\n",
      "I1128 20:57:58.364284 14512 learning.py:512] global step 330: loss = 3.0893 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 331: loss = 3.1534 (0.367 sec/step)\n",
      "I1128 20:57:58.733296 14512 learning.py:512] global step 331: loss = 3.1534 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 332: loss = 4.4971 (0.357 sec/step)\n",
      "I1128 20:57:59.092310 14512 learning.py:512] global step 332: loss = 4.4971 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 333: loss = 2.7929 (0.361 sec/step)\n",
      "I1128 20:57:59.455345 14512 learning.py:512] global step 333: loss = 2.7929 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 334: loss = 3.6618 (0.367 sec/step)\n",
      "I1128 20:57:59.822413 14512 learning.py:512] global step 334: loss = 3.6618 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 335: loss = 3.0570 (0.361 sec/step)\n",
      "I1128 20:58:00.184390 14512 learning.py:512] global step 335: loss = 3.0570 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 336: loss = 3.3211 (0.364 sec/step)\n",
      "I1128 20:58:00.550800 14512 learning.py:512] global step 336: loss = 3.3211 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 337: loss = 3.1098 (0.363 sec/step)\n",
      "I1128 20:58:00.914827 14512 learning.py:512] global step 337: loss = 3.1098 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 338: loss = 3.7253 (0.358 sec/step)\n",
      "I1128 20:58:01.274872 14512 learning.py:512] global step 338: loss = 3.7253 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 339: loss = 2.2284 (0.372 sec/step)\n",
      "I1128 20:58:01.647865 14512 learning.py:512] global step 339: loss = 2.2284 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 340: loss = 4.4163 (0.364 sec/step)\n",
      "I1128 20:58:02.013886 14512 learning.py:512] global step 340: loss = 4.4163 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 341: loss = 2.9163 (0.362 sec/step)\n",
      "I1128 20:58:02.376915 14512 learning.py:512] global step 341: loss = 2.9163 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 342: loss = 3.0059 (0.366 sec/step)\n",
      "I1128 20:58:02.744931 14512 learning.py:512] global step 342: loss = 3.0059 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 343: loss = 3.9704 (0.370 sec/step)\n",
      "I1128 20:58:03.115953 14512 learning.py:512] global step 343: loss = 3.9704 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 344: loss = 3.3686 (0.366 sec/step)\n",
      "I1128 20:58:03.483955 14512 learning.py:512] global step 344: loss = 3.3686 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 345: loss = 4.1089 (0.365 sec/step)\n",
      "I1128 20:58:03.850974 14512 learning.py:512] global step 345: loss = 4.1089 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 346: loss = 2.5383 (0.359 sec/step)\n",
      "I1128 20:58:04.212013 14512 learning.py:512] global step 346: loss = 2.5383 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 347: loss = 3.4347 (0.370 sec/step)\n",
      "I1128 20:58:04.583040 14512 learning.py:512] global step 347: loss = 3.4347 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 348: loss = 2.4433 (0.370 sec/step)\n",
      "I1128 20:58:04.955021 14512 learning.py:512] global step 348: loss = 2.4433 (0.370 sec/step)\n",
      "INFO:tensorflow:global step 349: loss = 2.4004 (0.371 sec/step)\n",
      "I1128 20:58:05.327059 14512 learning.py:512] global step 349: loss = 2.4004 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 350: loss = 4.3169 (0.367 sec/step)\n",
      "I1128 20:58:05.695890 14512 learning.py:512] global step 350: loss = 4.3169 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 351: loss = 3.4891 (0.355 sec/step)\n",
      "I1128 20:58:06.052936 14512 learning.py:512] global step 351: loss = 3.4891 (0.355 sec/step)\n",
      "INFO:tensorflow:global step 352: loss = 3.0829 (0.355 sec/step)\n",
      "I1128 20:58:06.408983 14512 learning.py:512] global step 352: loss = 3.0829 (0.355 sec/step)\n",
      "INFO:tensorflow:global step 353: loss = 2.5656 (0.364 sec/step)\n",
      "I1128 20:58:06.775004 14512 learning.py:512] global step 353: loss = 2.5656 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 354: loss = 2.6451 (0.367 sec/step)\n",
      "I1128 20:58:07.141587 14512 learning.py:512] global step 354: loss = 2.6451 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 355: loss = 4.0885 (0.362 sec/step)\n",
      "I1128 20:58:07.505614 14512 learning.py:512] global step 355: loss = 4.0885 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 356: loss = 2.8282 (0.361 sec/step)\n",
      "I1128 20:58:07.867617 14512 learning.py:512] global step 356: loss = 2.8282 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 357: loss = 3.0687 (0.363 sec/step)\n",
      "I1128 20:58:08.232568 14512 learning.py:512] global step 357: loss = 3.0687 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 358: loss = 3.5256 (0.357 sec/step)\n",
      "I1128 20:58:08.590507 14512 learning.py:512] global step 358: loss = 3.5256 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 359: loss = 2.9761 (0.360 sec/step)\n",
      "I1128 20:58:08.951521 14512 learning.py:512] global step 359: loss = 2.9761 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 360: loss = 2.4625 (0.364 sec/step)\n",
      "I1128 20:58:09.317537 14512 learning.py:512] global step 360: loss = 2.4625 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 361: loss = 3.6432 (0.358 sec/step)\n",
      "I1128 20:58:09.676576 14512 learning.py:512] global step 361: loss = 3.6432 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 362: loss = 2.7076 (0.359 sec/step)\n",
      "I1128 20:58:10.037611 14512 learning.py:512] global step 362: loss = 2.7076 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 363: loss = 3.2397 (0.360 sec/step)\n",
      "I1128 20:58:10.398652 14512 learning.py:512] global step 363: loss = 3.2397 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 364: loss = 2.4320 (0.367 sec/step)\n",
      "I1128 20:58:10.765664 14512 learning.py:512] global step 364: loss = 2.4320 (0.367 sec/step)\n",
      "INFO:tensorflow:global step 365: loss = 3.5423 (0.360 sec/step)\n",
      "I1128 20:58:11.127722 14512 learning.py:512] global step 365: loss = 3.5423 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 366: loss = 2.8206 (0.365 sec/step)\n",
      "I1128 20:58:11.494716 14512 learning.py:512] global step 366: loss = 2.8206 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 367: loss = 2.2200 (0.364 sec/step)\n",
      "I1128 20:58:11.858741 14512 learning.py:512] global step 367: loss = 2.2200 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 368: loss = 2.4674 (0.360 sec/step)\n",
      "I1128 20:58:12.220206 14512 learning.py:512] global step 368: loss = 2.4674 (0.360 sec/step)\n",
      "INFO:tensorflow:global step 369: loss = 3.1235 (0.371 sec/step)\n",
      "I1128 20:58:12.592211 14512 learning.py:512] global step 369: loss = 3.1235 (0.371 sec/step)\n",
      "INFO:tensorflow:global step 370: loss = 3.3282 (0.365 sec/step)\n",
      "I1128 20:58:12.958233 14512 learning.py:512] global step 370: loss = 3.3282 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 371: loss = 3.7020 (0.366 sec/step)\n",
      "I1128 20:58:13.326248 14512 learning.py:512] global step 371: loss = 3.7020 (0.366 sec/step)\n",
      "INFO:tensorflow:global step 372: loss = 2.9491 (0.361 sec/step)\n",
      "I1128 20:58:13.689277 14512 learning.py:512] global step 372: loss = 2.9491 (0.361 sec/step)\n",
      "INFO:tensorflow:global step 373: loss = 2.7767 (0.365 sec/step)\n",
      "I1128 20:58:14.056296 14512 learning.py:512] global step 373: loss = 2.7767 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 374: loss = 3.6776 (0.365 sec/step)\n",
      "I1128 20:58:14.422318 14512 learning.py:512] global step 374: loss = 3.6776 (0.365 sec/step)\n",
      "INFO:tensorflow:global step 375: loss = 2.6959 (0.372 sec/step)\n",
      "I1128 20:58:14.795319 14512 learning.py:512] global step 375: loss = 2.6959 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 376: loss = 2.4462 (0.369 sec/step)\n",
      "I1128 20:58:15.165329 14512 learning.py:512] global step 376: loss = 2.4462 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 377: loss = 3.5122 (0.368 sec/step)\n",
      "I1128 20:58:15.533349 14512 learning.py:512] global step 377: loss = 3.5122 (0.368 sec/step)\n",
      "INFO:tensorflow:global step 378: loss = 2.8387 (0.363 sec/step)\n",
      "I1128 20:58:15.897373 14512 learning.py:512] global step 378: loss = 2.8387 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 379: loss = 3.6320 (0.376 sec/step)\n",
      "I1128 20:58:16.274380 14512 learning.py:512] global step 379: loss = 3.6320 (0.376 sec/step)\n",
      "INFO:tensorflow:global step 380: loss = 3.6103 (0.375 sec/step)\n",
      "I1128 20:58:16.650359 14512 learning.py:512] global step 380: loss = 3.6103 (0.375 sec/step)\n",
      "INFO:tensorflow:global step 381: loss = 2.3791 (0.364 sec/step)\n",
      "I1128 20:58:17.015410 14512 learning.py:512] global step 381: loss = 2.3791 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 382: loss = 3.5592 (0.431 sec/step)\n",
      "I1128 20:58:17.448226 14512 learning.py:512] global step 382: loss = 3.5592 (0.431 sec/step)\n",
      "INFO:tensorflow:global step 383: loss = 2.6828 (0.390 sec/step)\n",
      "I1128 20:58:17.839179 14512 learning.py:512] global step 383: loss = 2.6828 (0.390 sec/step)\n",
      "INFO:tensorflow:global step 384: loss = 3.9172 (0.389 sec/step)\n",
      "I1128 20:58:18.229137 14512 learning.py:512] global step 384: loss = 3.9172 (0.389 sec/step)\n",
      "INFO:tensorflow:global step 385: loss = 2.6330 (0.369 sec/step)\n",
      "I1128 20:58:18.599147 14512 learning.py:512] global step 385: loss = 2.6330 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 386: loss = 1.9280 (0.363 sec/step)\n",
      "I1128 20:58:18.964188 14512 learning.py:512] global step 386: loss = 1.9280 (0.363 sec/step)\n",
      "INFO:tensorflow:global step 387: loss = 2.9627 (0.372 sec/step)\n",
      "I1128 20:58:19.337173 14512 learning.py:512] global step 387: loss = 2.9627 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 388: loss = 3.8817 (0.369 sec/step)\n",
      "I1128 20:58:19.707183 14512 learning.py:512] global step 388: loss = 3.8817 (0.369 sec/step)\n",
      "INFO:tensorflow:global step 389: loss = 3.3301 (0.356 sec/step)\n",
      "I1128 20:58:20.065241 14512 learning.py:512] global step 389: loss = 3.3301 (0.356 sec/step)\n",
      "INFO:tensorflow:global step 390: loss = 3.4865 (0.364 sec/step)\n",
      "I1128 20:58:20.429253 14512 learning.py:512] global step 390: loss = 3.4865 (0.364 sec/step)\n",
      "INFO:tensorflow:global step 391: loss = 3.2645 (0.372 sec/step)\n",
      "I1128 20:58:20.803258 14512 learning.py:512] global step 391: loss = 3.2645 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 392: loss = 3.4779 (0.362 sec/step)\n",
      "I1128 20:58:21.166281 14512 learning.py:512] global step 392: loss = 3.4779 (0.362 sec/step)\n",
      "INFO:tensorflow:global step 393: loss = 4.2555 (0.359 sec/step)\n",
      "I1128 20:58:21.526318 14512 learning.py:512] global step 393: loss = 4.2555 (0.359 sec/step)\n",
      "INFO:tensorflow:global step 394: loss = 3.5645 (0.358 sec/step)\n",
      "I1128 20:58:21.885358 14512 learning.py:512] global step 394: loss = 3.5645 (0.358 sec/step)\n",
      "INFO:tensorflow:global step 395: loss = 3.3623 (0.357 sec/step)\n",
      "I1128 20:58:22.244397 14512 learning.py:512] global step 395: loss = 3.3623 (0.357 sec/step)\n",
      "INFO:tensorflow:global step 396: loss = 2.6083 (0.372 sec/step)\n",
      "I1128 20:58:22.618398 14512 learning.py:512] global step 396: loss = 2.6083 (0.372 sec/step)\n",
      "INFO:tensorflow:global step 397: loss = 3.5135 (0.406 sec/step)\n",
      "I1128 20:58:23.024312 14512 learning.py:512] global step 397: loss = 3.5135 (0.406 sec/step)\n",
      "INFO:tensorflow:global step 398: loss = 3.4484 (0.382 sec/step)\n",
      "I1128 20:58:23.407288 14512 learning.py:512] global step 398: loss = 3.4484 (0.382 sec/step)\n",
      "INFO:tensorflow:global step 399: loss = 3.4456 (0.414 sec/step)\n",
      "I1128 20:58:23.822180 14512 learning.py:512] global step 399: loss = 3.4456 (0.414 sec/step)\n",
      "INFO:tensorflow:global step 400: loss = 2.9777 (0.405 sec/step)\n",
      "I1128 20:58:24.229090 14512 learning.py:512] global step 400: loss = 2.9777 (0.405 sec/step)\n",
      "INFO:tensorflow:global step 401: loss = 3.3137 (0.390 sec/step)"
     ]
    }
   ],
   "source": [
    "!python object_detection/train.py \\\n",
    "--logtostderr \\\n",
    "--train_dir=object_detection/training/ \\\n",
    "--pipeline_config_path=object_detection/training/ssd_mobilenet_v1_coco.config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/5.52m params)\n",
      "  BoxPredictor_0 (--/12.31k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/6.16k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
      "  BoxPredictor_1 (--/49.20k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/24.60k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
      "  BoxPredictor_2 (--/24.62k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "  BoxPredictor_3 (--/12.34k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "  BoxPredictor_4 (--/12.34k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "  BoxPredictor_5 (--/6.19k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "  FeatureExtractor (--/5.41m params)\n",
      "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "\n",
      "======================End of Report==========================\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/17.64k flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/add_2 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/add_5 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
      "  MultipleGridAnchorGenerator/add_8 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
      "  MultipleGridAnchorGenerator/add_11 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
      "  MultipleGridAnchorGenerator/add_14 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/add (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/add_1 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/add_17 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_3 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/add_4 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_7 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_6 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/add_10 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/add_9 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_13 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/add_12 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_15 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_16 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_18 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_19 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_20 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_21 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_22 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/add_23 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/add (1/1 flops)\n",
      "  Preprocessor/map/while/add_1 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.659727  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.696628  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.734527  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.771428  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.808330  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1128 21:00:47.846229  7708 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\post_processing.py:595: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1128 21:00:48.081599  7708 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\core\\post_processing.py:595: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:475: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W1128 21:00:48.446623  7708 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:475: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:654: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W1128 21:00:48.450612  7708 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:654: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W1128 21:00:48.450612  7708 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "Incomplete shape.\n",
      "2020-11-28 21:00:54.527795: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll\n",
      "2020-11-28 21:00:54.544044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 21:00:54.544058: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 21:00:54.544109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 21:00:54.544497: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-11-28 21:00:54.547158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 21:00:54.547166: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 21:00:54.547186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 21:00:54.878118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-28 21:00:54.878133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-11-28 21:00:54.878137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-11-28 21:00:54.878241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4767 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "122 ops no flops stats due to incomplete shapes.\n",
      "122 ops no flops stats due to incomplete shapes.\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W1128 21:00:54.881358  7708 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from object_detection/training/model.ckpt-500\n",
      "I1128 21:00:54.883354  7708 saver.py:1280] Restoring parameters from object_detection/training/model.ckpt-500\n",
      "2020-11-28 21:00:59.261993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 21:00:59.262006: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 21:00:59.262031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 21:00:59.262055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-28 21:00:59.262060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-11-28 21:00:59.262062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-11-28 21:00:59.262125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4767 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from object_detection/training/model.ckpt-500\n",
      "I1128 21:00:59.265110  7708 saver.py:1280] Restoring parameters from object_detection/training/model.ckpt-500\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W1128 21:00:59.603876  7708 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\tools\\freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W1128 21:00:59.603876  7708 deprecation.py:323] From C:\\Users\\ijan\\anaconda3\\envs\\py36-tf114\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 145 variables.\n",
      "I1128 21:01:00.029737  7708 graph_util_impl.py:311] Froze 145 variables.\n",
      "INFO:tensorflow:Converted 145 variables to const ops.\n",
      "I1128 21:01:00.190338  7708 graph_util_impl.py:364] Converted 145 variables to const ops.\n",
      "2020-11-28 21:01:00.565449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-28 21:01:00.565463: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
      "2020-11-28 21:01:00.565487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2020-11-28 21:01:00.565510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-28 21:01:00.565514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2020-11-28 21:01:00.565518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2020-11-28 21:01:00.565575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4767 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:385: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W1128 21:01:00.994052  7708 deprecation.py:323] From C:\\object-detections\\models-master\\models-master\\research\\object_detection\\exporter.py:385: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "I1128 21:01:00.995060  7708 builder_impl.py:636] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I1128 21:01:00.995060  7708 builder_impl.py:456] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: traffic_light_inference_graph\\saved_model\\saved_model.pb\n",
      "I1128 21:01:02.388445  7708 builder_impl.py:421] SavedModel written to: traffic_light_inference_graph\\saved_model\\saved_model.pb\n",
      "INFO:tensorflow:Writing pipeline config file to traffic_light_inference_graph\\pipeline.config\n",
      "I1128 21:01:02.401412  7708 config_util.py:254] Writing pipeline config file to traffic_light_inference_graph\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/export_inference_graph.py \\\n",
    "--input_type=image_tensor \\\n",
    "--pipeline_config_path=object_detection/training/ssd_mobilenet_v1_coco.config \\\n",
    "--trained_checkpoint_prefix=object_detection/training/model.ckpt-500 \\\n",
    "--output_directory=traffic_light_inference_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
